{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from datetime import datetime\n",
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "from transformers import GPT2LMHeadModel,AdamW,get_linear_schedule_with_warmup\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torch\n",
    "from torch.nn import CrossEntropyLoss\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "from tqdm import tnrange, tqdm_notebook\n",
    "\n",
    "from dataset import GPT21024Dataset \n",
    "from utils import add_special_tokens, generate_sample, set_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(batch_size=1, device=device(type='cuda'), gradient_accumulation_steps=2, ids_file='./CNN/ids.json', lr=5e-05, max_grad_norm=1.0, model_dir='./weights', n_gpu=1, num_train_epochs=1, num_workers=4, output_dir='./output', root_dir='./CNN/gpt2_1024_data', seed=42)\n"
     ]
    }
   ],
   "source": [
    "#please change default arguments if needed\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--lr\",default=5e-5, type=float, help=\"learning rate\")\n",
    "parser.add_argument(\"--seed\",default=42, type=int,  help=\"seed to replicate results\")\n",
    "parser.add_argument(\"--n_gpu\",default=1, type=int,  help=\"no of gpu available\")\n",
    "parser.add_argument(\"--gradient_accumulation_steps\",default=2, type=int, help=\"gradient_accumulation_steps\")\n",
    "parser.add_argument(\"--batch_size\",default=1, type=int,  help=\"batch_size\")\n",
    "parser.add_argument(\"--num_workers\",default=4, type=int,  help=\"num of cpus available\")\n",
    "parser.add_argument(\"--device\",default=torch.device(\"cuda\"), help=\"torch.device object\")\n",
    "parser.add_argument(\"--num_train_epochs\",default=1, type=int,  help=\"no of epochs of training\")\n",
    "parser.add_argument(\"--output_dir\",default='./output', type=str,  help=\"path to save evaluation results\")\n",
    "parser.add_argument(\"--model_dir\",default='./weights', type=str,  help=\"path to save trained model\")\n",
    "parser.add_argument(\"--max_grad_norm\",default=1.0, type=float, help=\"max gradient norm.\")\n",
    "parser.add_argument(\"--root_dir\",default='./CNN/gpt2_1024_data', type=str, help=\"location of json dataset.\")\n",
    "parser.add_argument(\"--ids_file\",default='./CNN/ids.json', type=str, help=\"location of train, valid and test file indexes\")\n",
    "args = parser.parse_args([])\n",
    "print(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(args, model, tokenizer, train_dataset, valid_dataset, ignore_index):\n",
    "    \"\"\" Trains GPT2 model and logs necessary details.\n",
    "        Args:\n",
    "            args: dict that contains all the necessary information passed by user while training\n",
    "            model: finetuned gpt/gpt2 model\n",
    "            tokenizer: GPT/GPT2 tokenizer\n",
    "            train_dataset: GPT21024Dataset object for training data\n",
    "            ignore_index: token not considered in loss calculation\n",
    "    \"\"\"\n",
    "    writer = SummaryWriter('./output/logs')\n",
    "    train_sampler = RandomSampler(train_dataset)\n",
    "    train_dl = DataLoader(train_dataset,sampler=train_sampler,batch_size=args.batch_size,num_workers=args.num_workers)\n",
    "    loss_fct = CrossEntropyLoss(ignore_index=ignore_index) #ignores padding token for loss calculation\n",
    "    optimizer = AdamW(model.parameters(),lr=args.lr)\n",
    "    # scheduler = WarmupLinearSchedule(optimizer,100,80000)\n",
    "    scheduler = get_linear_schedule_with_warmup(optimizer,100,80000)\n",
    "    global_step = 0\n",
    "    tr_loss, logging_loss = 0.0, 0.0\n",
    "    model.zero_grad()\n",
    "    train_iterator = tnrange(int(args.num_train_epochs), desc=\"Epoch\")\n",
    "    set_seed(args)\n",
    "    for _ in train_iterator:\n",
    "        epoch_iterator = tqdm_notebook(train_dl, desc=\"Training\")\n",
    "        for step, batch in enumerate(epoch_iterator):\n",
    "            inputs, labels = batch['article'].to(args.device), batch['article'].to(args.device)\n",
    "            model.train()\n",
    "            logits = model(inputs)[0]\n",
    "            # only consider loss on reference summary just like seq2seq models\n",
    "            shift_logits = logits[..., batch['sum_idx']:-1, :].contiguous()\n",
    "            shift_labels = labels[..., batch['sum_idx']+1:].contiguous()\n",
    "            loss = loss_fct(shift_logits.view(-1, shift_logits.size(-1)), shift_labels.view(-1))\n",
    "            loss = loss/args.gradient_accumulation_steps\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), args.max_grad_norm)\n",
    "            tr_loss += loss.item()\n",
    "            if (step + 1) % args.gradient_accumulation_steps == 0:\n",
    "                optimizer.step()\n",
    "                scheduler.step()  # Update learning rate schedule\n",
    "                model.zero_grad()\n",
    "                global_step += 1\n",
    "                writer.add_scalar('lr', scheduler.get_lr()[0], global_step)\n",
    "                writer.add_scalar('loss', (tr_loss - logging_loss)/args.gradient_accumulation_steps, global_step)\n",
    "                logging_loss = tr_loss\n",
    "                print(\"loss:\", loss.item(), end='\\n\\n')\n",
    "                if (step + 1)/args.gradient_accumulation_steps == 1.0:\n",
    "                \tprint('After 1st update: ', end='\\n\\n')\n",
    "                \tgenerate_sample(valid_dataset, tokenizer, model, num=2, eval_step=False,device=args.device)\n",
    "                \n",
    "                \n",
    "            if (step + 1) % (10*args.gradient_accumulation_steps) == 0:\n",
    "                results = evaluate(args, model, valid_dataset, ignore_index, global_step)\n",
    "                for key, value in results.items():\n",
    "                    writer.add_scalar('eval_{}'.format(key), value, global_step)\n",
    "                print('After', global_step+1,'updates: ', end='\\n\\n')\n",
    "                generate_sample(valid_dataset, tokenizer, num=2, eval_step=True,device=args.device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(args, model, eval_dataset, ignore_index, global_step=None):\n",
    "    \"\"\" Returns perplexity score on validation dataset.\n",
    "        Args:\n",
    "            args: dict that contains all the necessary information passed by user while training\n",
    "            model: finetuned gpt/gpt2 model\n",
    "            eval_dataset: GPT21024Dataset object for validation data\n",
    "            global_step: no. of times gradients have backpropagated\n",
    "            ignore_index: token not considered in loss calculation\n",
    "    \"\"\"\n",
    "    if not os.path.exists(args.output_dir):\n",
    "        os.mkdir(args.output_dir)\n",
    "    eval_output_dir = args.output_dir\n",
    "\n",
    "    results = {}\n",
    "    eval_sampler = SequentialSampler(eval_dataset)\n",
    "    eval_dataloader = DataLoader(eval_dataset, sampler=eval_sampler, batch_size=args.batch_size)\n",
    "    loss_fct = CrossEntropyLoss(ignore_index=ignore_index) #ignores padding token for loss calculation\n",
    "\n",
    "    eval_loss = 0.0\n",
    "    nb_eval_steps = 0\n",
    "    model.eval()\n",
    "\n",
    "    for batch in tqdm_notebook(eval_dataloader, desc=\"Evaluating\"):\n",
    "        inputs, labels = batch['article'].to(args.device), batch['article'].to(args.device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            logits = model(inputs)[0]\n",
    "            idx = batch['sum_idx'].item() # index of separator token\n",
    "            # only consider loss on reference summary just like seq2seq models\n",
    "            shift_logits = logits[..., batch['sum_idx']:-1, :].contiguous()\n",
    "            shift_labels = labels[..., batch['sum_idx']+1:].contiguous()\n",
    "            lm_loss = loss_fct(shift_logits.view(-1, shift_logits.size(-1)), shift_labels.view(-1))\n",
    "            eval_loss += lm_loss.mean().item()\n",
    "        nb_eval_steps += 1\n",
    "\n",
    "    eval_loss = eval_loss / nb_eval_steps\n",
    "    perplexity = torch.exp(torch.tensor(eval_loss))\n",
    "\n",
    "    result = {\n",
    "        \"perplexity\": perplexity\n",
    "    }\n",
    "    print(\"perplexity:\", perplexity.item())\n",
    "\n",
    "    if global_step:\n",
    "        output_eval_file = os.path.join(eval_output_dir, \"eval_results.txt\")\n",
    "        with open(output_eval_file, \"a\") as f:\n",
    "            for key in sorted(result.keys()):\n",
    "                f.write('\\n\\n')\n",
    "                f.write(\"time = %s, %s = %s, step = %s\\n\" % (datetime.now().strftime(\"%d/%m/%Y %H:%M:%S\"), key, str(result[key]), str(global_step)))\n",
    "    return result           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000 {'article': tensor([   12,    43, 27912,  ..., 50257, 50257, 50257]), 'sum_idx': 251}\n",
      "500 {'article': tensor([   12,    43, 27912,  ..., 50257, 50257, 50257]), 'sum_idx': 231}\n"
     ]
    }
   ],
   "source": [
    "# creating training and validation dataset object\n",
    "\n",
    "train_data = GPT21024Dataset(args.root_dir,args.ids_file,mode='train',length=3000) #training on only 3000 datasets\n",
    "valid_data = GPT21024Dataset(args.root_dir,args.ids_file,mode='valid',length=500)  #validation on only 500 datasets\n",
    "print(len(train_data),train_data[4])\n",
    "print(len(valid_data),valid_data[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'\\xd9\\x11\\x00\\x00\\x00\\x00\\x00\\x00\\n\\xd6#\\n\\xdf\\x02\\n\\x08abstract\\x12\\xd2\\x02\\n\\xcf\\x02\\n\\xcc\\x02<s> mentally ill inmates in miami are housed on the `` forgotten floor \\'\\' </s> <s> judge steven leifman says most are there as a result of `` avoidable felonies \\'\\' </s> <s> while cnn tours facility , patient shouts : `` i am the son of the president \\'\\' </s> <s> leifman says the system is unjust and he \\'s fighting for change . </s>\\n\\xf1 \\n\\x07article\\x12\\xe5 \\n\\xe2 \\n\\xdf editor \\'s note : in our behind the scenes series , cnn correspondents share their experiences in covering news and analyze the stories behind the events . here , soledad o\\'brien takes users inside a jail where many of the inmates are mentally ill . an inmate housed on the `` forgotten floor , \\'\\' where many mentally ill inmates are housed in miami before trial . miami , florida -lrb- cnn -rrb- -- the ninth floor of the miami-dade pretrial detention facility is dubbed the `` forgotten floor . \\'\\' here , inmates with the most severe mental illnesses are incarcerated until they \\'re ready to appear in court . most often , they face drug charges or charges of assaulting an officer -- charges that judge steven leifman says are usually `` avoidable felonies . \\'\\' he says the arrests often result from confrontations with police . mentally ill people often wo n\\'t do what they \\'re told when police arrive on the scene -- confrontation seems to exacerbate their illness and they become more paranoid , delusional , and less likely to follow directions , according to leifman . so , they end up on the ninth floor severely mentally disturbed , but not getting any real help because they \\'re in jail . we toured the jail with leifman . he is well known in miami as an advocate for justice and the mentally ill . even though we were not exactly welcomed with open arms by the guards , we were given permission to shoot videotape and tour the floor . go inside the ` forgotten floor \\' \\'\\' at first , it \\'s hard to determine where the people are . the prisoners are wearing sleeveless robes . imagine cutting holes for arms and feet in a heavy wool sleeping bag -- that \\'s kind of what they look like . they \\'re designed to keep the mentally ill patients from injuring themselves . that \\'s also why they have no shoes , laces or mattresses . leifman says about one-third of all people in miami-dade county jails are mentally ill . so , he says , the sheer volume is overwhelming the system , and the result is what we see on the ninth floor . of course , it is a jail , so it \\'s not supposed to be warm and comforting , but the lights glare , the cells are tiny and it \\'s loud . we see two , sometimes three men -- sometimes in the robes , sometimes naked , lying or sitting in their cells . `` i am the son of the president . you need to get me out of here ! \\'\\' one man shouts at me . he is absolutely serious , convinced that help is on the way -- if only he could reach the white house . leifman tells me that these prisoner-patients will often circulate through the system , occasionally stabilizing in a mental hospital , only to return to jail to face their charges . it \\'s brutally unjust , in his mind , and he has become a strong advocate for changing things in miami . over a meal later , we talk about how things got this way for mental patients . leifman says 200 years ago people were considered `` lunatics \\'\\' and they were locked up in jails even if they had no charges against them . they were just considered unfit to be in society . over the years , he says , there was some public outcry , and the mentally ill were moved out of jails and into hospitals . but leifman says many of these mental hospitals were so horrible they were shut down . where did the patients go ? nowhere . the streets . they became , in many cases , the homeless , he says . they never got treatment . leifman says in 1955 there were more than half a million people in state mental hospitals , and today that number has been reduced 90 percent , and 40,000 to 50,000 people are in mental hospitals . the judge says he \\'s working to change this . starting in 2008 , many inmates who would otherwise have been brought to the `` forgotten floor \\'\\' will instead be sent to a new mental health facility -- the first step on a journey toward long-term treatment , not just punishment . leifman says it \\'s not the complete answer , but it \\'s a start . leifman says the best part is that it \\'s a win-win solution . the patients win , the families are relieved , and the state saves money by simply not cycling these prisoners through again and again . and , for leifman , justice is served . e-mail to a friend .\\x89\\x0b\\x00\\x00\\x00\\x00\\x00\\x00\\n\\x86\\x17\\n\\x89\\x02\\n\\x08abstract\\x12\\xfc\\x01\\n\\xf9\\x01\\n\\xf6\\x01<s> harry potter star daniel radcliffe gets # 20m fortune as he turns 18 monday . </s> <s> young actor says he has no plans to fritter his cash away . </s> <s> radcliffe \\'s earnings from first five potter films have been held in trust fund . </s>\\n\\xf7\\x14\\n\\x07article\\x12\\xeb\\x14\\n\\xe8\\x14\\n\\xe5\\x14london , england -lrb- reuters -rrb- -- harry potter star daniel radcliffe gains access to a reported # 20 million -lrb- $ 41.1 million -rrb- fortune as he turns 18 on monday , but he insists the money wo n\\'t cast a spell on him . daniel radcliffe as harry potter in `` harry potter and the order of the phoenix \\'\\' to the disappointment of gossip columnists around the world , the young actor says he has no plans to fritter his cash away on fast cars , drink and celebrity parties . `` i do n\\'t plan to be one of those people who , as soon as they turn 18 , suddenly buy themselves a massive sports car collection or something similar , \\'\\' he told an australian interviewer earlier this month . `` i do n\\'t think i \\'ll be particularly extravagant . `` the things i like buying are things that cost about 10 pounds -- books and cds and dvds . \\'\\' at 18 , radcliffe will be able to gamble in a casino , buy a drink in a pub or see the horror film `` hostel : part ii , \\'\\' currently six places below his number one movie on the uk box office chart . details of how he \\'ll mark his landmark birthday are under wraps . his agent and publicist had no comment on his plans . `` i \\'ll definitely have some sort of party , \\'\\' he said in an interview . `` hopefully none of you will be reading about it . \\'\\' radcliffe \\'s earnings from the first five potter films have been held in a trust fund which he has not been able to touch . despite his growing fame and riches , the actor says he is keeping his feet firmly on the ground . `` people are always looking to say ` kid star goes off the rails , \\' \\'\\' he told reporters last month . `` but i try very hard not to go that way because it would be too easy for them . \\'\\' his latest outing as the boy wizard in `` harry potter and the order of the phoenix \\'\\' is breaking records on both sides of the atlantic and he will reprise the role in the last two films . watch i-reporter give her review of potter \\'s latest \\'\\' there is life beyond potter , however . the londoner has filmed a tv movie called `` my boy jack , \\'\\' about author rudyard kipling and his son , due for release later this year . he will also appear in `` december boys , \\'\\' an australian film about four boys who escape an orphanage . earlier this year , he made his stage debut playing a tortured teenager in peter shaffer \\'s `` equus . \\'\\' meanwhile , he is braced for even closer media scrutiny now that he \\'s legally an adult : `` i just think i \\'m going to be more sort of fair game , \\'\\' he told reuters . e-mail to a friend . copyright 2007 reuters . all rights reserved.this material may not be published , broadcast , rewritten , or redistributed .Q\\x11\\x00\\x00\\x00\\x00\\x00\\x00\\n\\xce\"\\n\\xa5\\x02\\n\\x08abstract\\x12\\x98\\x02\\n\\x95\\x02\\n\\x92\\x02<s> new : `` i thought i was going to die , \\'\\' driver says . </s> <s> man says pickup truck was folded in half ; he just has cut on face . </s> <s> driver : `` i probably had a 30 - , 35-foot free fall \\'\\' </s> <s> minnesota bridge collapsed during rush hour wednesday . </s>\\n\\xa3 \\n\\x07article\\x12\\x97 \\n\\x94 \\n\\x91 minneapolis , minnesota -lrb- cnn -rrb- -- drivers who were on the minneapolis bridge when it collapsed told harrowing tales of survival . `` the whole bridge from one side of the mississippi to the other just completely gave way , fell all the way down , \\'\\' survivor gary babineau told cnn . `` i probably had a 30 - , 35-foot free fall . and there \\'s cars in the water , there \\'s cars on fire . the whole bridge is down . \\'\\' he said his back was injured but he determined he could move around . `` i realized there was a school bus right next to me , and me and a couple of other guys went over and started lifting the kids off the bridge . they were yelling , screaming , bleeding . i think there were some broken bones . \\'\\' watch a driver describe his narrow escape \\'\\' at home when he heard about the disaster , dr. john hink , an emergency room physician , jumped into his car and rushed to the scene in 15 minutes . he arrived at the south side of the bridge , stood on the riverbank and saw dozens of people lying dazed on an expansive deck . they were in the middle of the mississippi river , which was churning fast , and he had no way of getting to them . he went to the north side , where there was easier access to people . ambulances were also having a hard time driving down to the river to get closer to the scene . working feverishly , volunteers , emts and other officials managed to get 55 people into ambulances in less than two hours . occasionally , a pickup truck with a medic inside would drive to get an injured person and bring him back up even ground , hink told cnn . the rescue effort was controlled and organized , he said ; the opposite of the lightning-quick collapse . `` i could see the whole bridge as it was going down , as it was falling , \\'\\' babineau said . `` it just gave a rumble real quick , and it all just gave way , and it just fell completely , all the way to the ground . and there was dust everywhere and it was just like everyone has been saying : it was just like out of the movies . \\'\\' babineau said the rear of his pickup truck was dangling over the edge of a broken-off section of t'\n"
     ]
    }
   ],
   "source": [
    "with open('/ssd3/xiaojingwu/Generating_Text_Summary_With_GPT2/CNN/finished_files/train.bin', 'rb') as f:\n",
    "    data = f.read(10000)\n",
    "    # text = data.decode('utf-8')\n",
    "    # lines = text.split('\\n')\n",
    "    print(data)\n",
    "\n",
    "# from datasets import load_dataset\n",
    "# dataset = load_dataset(\"cnn_dailymail\",'3.0.0', cache_dir=\"./dataset\")\n",
    "# dataset.save_to_disk('dataset/cnn_dailymail')\n",
    "# print(len(dataset['train']))\n",
    "# print(len(dataset['test']))\n",
    "# print(dataset['train'][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'rouge-1': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-2': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-l': {'r': 0.0, 'p': 0.0, 'f': 0.0}}]\n",
      "torch.Size([1, 3])\n"
     ]
    }
   ],
   "source": [
    "from rouge import Rouge\n",
    "\n",
    "# 假设这是参考摘要\n",
    "reference = \"天气预报说今天会下雨，请记得带伞。\"\n",
    "\n",
    "# 假设这是模型生成的摘要\n",
    "generated = \"今天可能有雨，出门时携带雨伞。\"\n",
    "\n",
    "# 初始化ROUGE计算器\n",
    "rouge = Rouge()\n",
    "\n",
    "# 计算并打印分数\n",
    "scores = rouge.get_scores(generated, reference)\n",
    "\n",
    "print(scores)\n",
    "a = torch.tensor([[1,2,3]])\n",
    "print(a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# load pretrained GPT2\n",
    "tokenizer = add_special_tokens()\n",
    "ignore_idx = tokenizer.pad_token_id\n",
    "\n",
    "# \n",
    "# \n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GPT2LMHeadModel.from_pretrained('/ssd3/xiaojingwu/gpt2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import GPT2Tokenizer, GPT2Model\n",
    "# tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "# model = GPT2Model.from_pretrained('gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(50259, 768)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.to(args.device)\n",
    "gpus= [0, 1, 2, 3, 4, 5, 6, 7]\n",
    "model = torch.nn.DataParallel(model.to(args.device), device_ids=gpus, output_device=gpus[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xiaojingwu/anaconda3/envs/env1/lib/python3.7/site-packages/transformers/optimization.py:415: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "/home/xiaojingwu/anaconda3/envs/env1/lib/python3.7/site-packages/ipykernel_launcher.py:20: TqdmDeprecationWarning: Please use `tqdm.notebook.trange` instead of `tqdm.tnrange`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "703d66b36bd04f3e81e2bcb3f27877d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xiaojingwu/anaconda3/envs/env1/lib/python3.7/site-packages/ipykernel_launcher.py:23: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4820df5b28c409b825a0a3ba2bfcf22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/3000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "Unconvertible NCCL type",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_25838/3076434413.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'total time: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\" minutes\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\\n\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_25838/239711181.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(args, model, tokenizer, train_dataset, valid_dataset, ignore_index)\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'article'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'article'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m             \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m             \u001b[0;31m# only consider loss on reference summary just like seq2seq models\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0mshift_logits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sum_idx'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/env1/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/env1/lib/python3.7/site-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    158\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m         \u001b[0mreplicas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/env1/lib/python3.7/site-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mreplicate\u001b[0;34m(self, module, device_ids)\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreplicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mreplicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/env1/lib/python3.7/site-packages/torch/nn/parallel/replicate.py\u001b[0m in \u001b[0;36mreplicate\u001b[0;34m(network, devices, detach)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0mbuffer_copies_rg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_broadcast_coalesced_reshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffers_rg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdetach\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m     \u001b[0mbuffer_copies_not_rg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_broadcast_coalesced_reshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffers_not_rg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdetach\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0mmodules\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/env1/lib/python3.7/site-packages/torch/nn/parallel/replicate.py\u001b[0m in \u001b[0;36m_broadcast_coalesced_reshape\u001b[0;34m(tensors, devices, detach)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_functions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBroadcast\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdetach\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcomm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast_coalesced\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;31m# Use the autograd function to broadcast if not detach\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/env1/lib/python3.7/site-packages/torch/nn/parallel/comm.py\u001b[0m in \u001b[0;36mbroadcast_coalesced\u001b[0;34m(tensors, devices, buffer_size)\u001b[0m\n\u001b[1;32m     54\u001b[0m     \"\"\"\n\u001b[1;32m     55\u001b[0m     \u001b[0mdevices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_get_device_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdevices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_broadcast_coalesced\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Unconvertible NCCL type"
     ]
    }
   ],
   "source": [
    "#training the model\n",
    "\n",
    "start = time.time()\n",
    "train(args, model, tokenizer, train_data, valid_data, ignore_idx)\n",
    "print('total time: ', (time.time()-start)/60, \" minutes\", end='\\n\\n')\n",
    "\n",
    "print('Saving trained model...')\n",
    "model_file = os.path.join(args.model_dir, 'model_data{}_trained_after_{}_epochs_only_sum_loss_ignr_pad.bin'.format(len(train_data),args.num_train_epochs))\n",
    "config_file = os.path.join(args.model_dir, 'config_data{}_trained_after_{}_epochs_only_sum_loss_ignr_pad.json'.format(len(train_data),args.num_train_epochs))\n",
    "torch.save(model.state_dict(), model_file)\n",
    "model.config.to_json_file(config_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "8852a54fd2219f215f04f8489b3e4d3bc652aafe982d5654a16e97443c572538"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
